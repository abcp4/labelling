{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import io\n",
    "import json\n",
    "import shutil\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "img_dir='/home/kiki/dados_servidor/Servidor/Teses/deepsearch_dataset/images/'\n",
    "bboxes_dir='/home/kiki/dados_servidor/Servidor/Teses/deepsearch_dataset/bboxes/'\n",
    "\n",
    "\n",
    "images_folders=os.listdir(img_dir)[:10]\n",
    "\n",
    "images_paths = []\n",
    "coordinates=[]\n",
    "classes=[]\n",
    "\n",
    "\n",
    "#convert images,coordinates and classes to a yolo dataset format\n",
    "def to_yolo(images_paths,coordinates,classes,yolo_folder):\n",
    "    for image in images_paths:\n",
    "        shutil.copy(image,yolo_folder)\n",
    "    for i in range(len(images_paths)):\n",
    "        with io.open(yolo_folder+'/'+images_paths[i].split('/')[-1].split('.')[0]+'.txt','w',encoding='utf8') as f:\n",
    "            for j in range(len(coordinates[i])):\n",
    "                f.write(str(classes[i][j])+' '+str(coordinates[i][j][0])+' '+str(coordinates[i][j][1])+' '+str(coordinates[i][j][2])+' '+str(coordinates[i][j][3])+'\\n')\n",
    "\n",
    "def convert(size, box):\n",
    "    dw = 1./size[0]\n",
    "    dh = 1./size[1]\n",
    "    x = (box[0] + box[1])/2.0\n",
    "    y = (box[2] + box[3])/2.0\n",
    "    w = box[1] - box[0]\n",
    "    h = box[3] - box[2]\n",
    "    x = x*dw\n",
    "    w = w*dw\n",
    "    y = y*dh\n",
    "    h = h*dh\n",
    "    return (x,y,w,h)\n",
    "\n",
    "# labels_dict={'title':1,'paragraph':2,'picture':3,'table':4,'formula':5,'footnote':6,'page-footer':7,'page-header':8,'subtitle-level-1':9,'caption':10}\n",
    "labels_dict={'caption':0,'footnote':1,'formula':2,'page-footer':3,'page-header':4,'paragraph':5,'picture':6,'subtitle-level-1':7,'table':8,'title':9}\n",
    "# labels_dict={'caption':1,'footnote':2,'formula':3,'page-footer':4,'page-header':5,'paragraph':6,'picture':7,'subtitle-level-1':8,'table':9,'title':10}\n",
    "\n",
    "resolution=150\n",
    "base_path='/home/kiki/dados_servidor/Servidor/Teses/labeling/dataset/'\n",
    "for folder in images_folders:\n",
    "    \n",
    "    annotations=json.load(open((bboxes_dir+folder+'.json')))\n",
    "    #mkdir\n",
    "    if not os.path.exists(base_path+folder):\n",
    "        os.mkdir(base_path+folder)\n",
    "    if not os.path.exists(base_path+folder+'/obj_train_data'):\n",
    "        os.mkdir(base_path+folder+'/obj_train_data')\n",
    "    for annotation in annotations.keys():\n",
    "        img_path=img_dir+folder+'/'+folder+'_'+annotation+'.jpg'\n",
    "        images_paths.append(img_path)\n",
    "        im=Image.open(img_path)\n",
    "        w= int(im.size[0])\n",
    "        h= int(im.size[1])\n",
    "        bboxes=[an['bbox'] for an in annotations[annotation]]\n",
    "        bboxes = [[x * resolution / 72 for x in b] for b in bboxes]\n",
    "        for i in range(len(bboxes)):\n",
    "            bbox=bboxes[i]\n",
    "            x_min,y_min,x_max,y_max=int(bbox[0]),int(bbox[1]),int(bbox[2]),int(bbox[3])\n",
    "            #convert to yolo format (x_center,y_center,width,height)\n",
    "            bbox=convert((w,h),(x_min,x_max,y_min,y_max))\n",
    "            bboxes[i]=bbox\n",
    "        \n",
    "        coordinates.append(bboxes)\n",
    "        # classes.append([an['type'] for an in annotations[annotation]])\n",
    "        classes.append([labels_dict[an['type']] for an in annotations[annotation]])\n",
    "    yolo_folder=base_path+folder+'/obj_train_data'\n",
    "    to_yolo(images_paths,coordinates,classes,yolo_folder)\n",
    "\n",
    "    p='/home/kiki/dados_servidor/Servidor/Teses/labeling/dataset/'+folder+'/'\n",
    "    #obj names\n",
    "    with io.open(p+'obj.names','w',encoding='utf8') as f:\n",
    "        for key in labels_dict.keys():\n",
    "            f.write(key.replace('-','_')+'\\n')\n",
    "    #train txt\n",
    "    with io.open(p+'train.txt','w',encoding='utf8') as f:\n",
    "        for image in images_paths:\n",
    "            f.write('data/obj_train_data/'+image.split('/')[-1]+'\\n')\n",
    "    #obj data\n",
    "    with io.open(p+'obj.data','w',encoding='utf8') as f:\n",
    "        f.write('classes = '+str(len(labels_dict.keys()))+'\\n')\n",
    "        # f.write('classes = '+str(len(labels_dict.keys())+1)+'\\n')\n",
    "        f.write('train = data/train.txt\\n')\n",
    "        # f.write('valid = data/train.txt\\n')\n",
    "        f.write('names = data/obj.names\\n')\n",
    "        f.write('backup = backup/\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "teses",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
